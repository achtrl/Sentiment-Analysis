{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwFSnTx6lhDP"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkEcVQX6lsFV"
      },
      "source": [
        "## Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjgb4V_qlgW_",
        "outputId": "ddfedf00-5441-4b7d-d47e-6d88907e23e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rtikEZlmDEz"
      },
      "source": [
        "##Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL0PwozUmNk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898a0778-6550-4db7-99b9-56651df6c76b"
      },
      "source": [
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVQUmH6imb2G"
      },
      "source": [
        "##Import and explore data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "diMTK8x9mhM9",
        "outputId": "abf6e1f8-b96e-4125-e0df-de7c1ed1cd38"
      },
      "source": [
        "data = pd.read_csv('gdrive/MyDrive/Colab Notebooks/Sentiment-Analysis/data/sentiment.csv', encoding = \"latin-1\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1467810369</th>\n",
              "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
              "      <th>NO_QUERY</th>\n",
              "      <th>_TheSpecialOne_</th>\n",
              "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
              "0  0  ...  is upset that he can't update his Facebook by ...                                                                  \n",
              "1  0  ...  @Kenichan I dived many times for the ball. Man...                                                                  \n",
              "2  0  ...    my whole body feels itchy and like its on fire                                                                   \n",
              "3  0  ...  @nationwideclass no, it's not behaving at all....                                                                  \n",
              "4  0  ...                      @Kwesidei not the whole crew                                                                   \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p653DSWmvpB"
      },
      "source": [
        "We need to rename the columns and we can get rid of all the useless data. To build our sentiment analysis model, we only need the text and the sentiment columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3fsfLNSTmnOO",
        "outputId": "e72cfb7f-4029-4882-f4c0-56a7e7377652"
      },
      "source": [
        "data.columns = ['Sentiment', 'ids', 'Date', 'Flag', 'User', 'Text']\n",
        "data.drop(['ids', 'Flag', 'Date', 'User'], axis=1, inplace=True)\n",
        "data = data.sample(frac=1) # shuffle the data\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1406450</th>\n",
              "      <td>4</td>\n",
              "      <td>@Alan_Wilbourn That's what we had for breakfas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225324</th>\n",
              "      <td>4</td>\n",
              "      <td>Its a beautiful day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824245</th>\n",
              "      <td>4</td>\n",
              "      <td>@kcmpls I'm glad someone thinks the maple syru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1270128</th>\n",
              "      <td>4</td>\n",
              "      <td>@shamara99 your background is STILL there on m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343476</th>\n",
              "      <td>0</td>\n",
              "      <td>Isn't online business great... What a cool gen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Sentiment                                               Text\n",
              "1406450          4  @Alan_Wilbourn That's what we had for breakfas...\n",
              "1225324          4                               Its a beautiful day \n",
              "824245           4  @kcmpls I'm glad someone thinks the maple syru...\n",
              "1270128          4  @shamara99 your background is STILL there on m...\n",
              "343476           0  Isn't online business great... What a cool gen..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz_0KB3BnUeo",
        "outputId": "beecb40e-b06f-44d1-c61f-3b2b629e46ea"
      },
      "source": [
        "data['Sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    800000\n",
              "0    799999\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMADpO7IpY0T"
      },
      "source": [
        "##Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjxp-tnrpbEd"
      },
      "source": [
        "The sentiment column has 2 different values : 0 for negative and 4 for positive. Let's replace them by 'positive' and 'negative' so that it is easier to read and we'll use the factorize method later to encode it for our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "60xtf1sppem2",
        "outputId": "4fab55c1-3e0b-45d7-c3c8-6801853faa4a"
      },
      "source": [
        "data.Sentiment.replace(4, 'positive', inplace=True)\n",
        "data.Sentiment.replace(0, 'negative', inplace=True)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1406450</th>\n",
              "      <td>positive</td>\n",
              "      <td>@Alan_Wilbourn That's what we had for breakfas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225324</th>\n",
              "      <td>positive</td>\n",
              "      <td>Its a beautiful day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824245</th>\n",
              "      <td>positive</td>\n",
              "      <td>@kcmpls I'm glad someone thinks the maple syru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1270128</th>\n",
              "      <td>positive</td>\n",
              "      <td>@shamara99 your background is STILL there on m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343476</th>\n",
              "      <td>negative</td>\n",
              "      <td>Isn't online business great... What a cool gen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentiment                                               Text\n",
              "1406450  positive  @Alan_Wilbourn That's what we had for breakfas...\n",
              "1225324  positive                               Its a beautiful day \n",
              "824245   positive  @kcmpls I'm glad someone thinks the maple syru...\n",
              "1270128  positive  @shamara99 your background is STILL there on m...\n",
              "343476   negative  Isn't online business great... What a cool gen..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_BrpIJtpiUZ"
      },
      "source": [
        "Now we need to preprocess the text. We need to lower it, get rid of usernames, numbers and emojis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNtW11Md3V4Y"
      },
      "source": [
        "# Defining dictionary containing all emojis with their meanings.\n",
        "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
        "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
        "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
        "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
        "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
        "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
        "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
        "\n",
        "# Defining regex patterns.\n",
        "urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "userPattern = '@[^\\s]+'\n",
        "alphaPattern = \"\\w*\\d{1,}\\w*\"\n",
        "sequencePattern = r\"(.)\\1\\1+\"\n",
        "seqReplacePattern = r\"\\1\\1\""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "re_G5WhA3aFO",
        "outputId": "88248d4a-7c67-46a5-ed9b-9c6ea737e8d6"
      },
      "source": [
        "t = time.time()\n",
        "\n",
        "data['Preprocessed text'] = pd.Series(dtype='object')\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "  text = row.Text.lower()\n",
        "  # Replace all URls with 'URL'\n",
        "  text = re.sub(urlPattern,' URL',text)\n",
        "  # Replace all emojis.\n",
        "  for emoji in emojis.keys():\n",
        "      text = text.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
        "  # Replace @USERNAME to 'USER'.\n",
        "  text = re.sub(userPattern,' USER', text)        \n",
        "  # Replace all non alphabets.\n",
        "  text = re.sub(alphaPattern, \" \", text)\n",
        "  # Replace 3 or more consecutive letters by 2 letter.\n",
        "  text = re.sub(sequencePattern, seqReplacePattern, text)\n",
        "\n",
        "  preprocessed = \"\"\n",
        "  for word in text.split():\n",
        "    if not word in list(nltk.corpus.stopwords.words('english')):\n",
        "      preprocessed += (word + ' ')\n",
        "\n",
        "  row['Preprocessed text'] = preprocessed\n",
        "\n",
        "print(f'Time Taken: {round(time.time()-t)} seconds')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time Taken: 2770 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "      <th>Preprocessed text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1406450</th>\n",
              "      <td>positive</td>\n",
              "      <td>@Alan_Wilbourn That's what we had for breakfas...</td>\n",
              "      <td>USER that's breakfast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225324</th>\n",
              "      <td>positive</td>\n",
              "      <td>Its a beautiful day</td>\n",
              "      <td>beautiful day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824245</th>\n",
              "      <td>positive</td>\n",
              "      <td>@kcmpls I'm glad someone thinks the maple syru...</td>\n",
              "      <td>USER i'm glad someone thinks maple syrup liquo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1270128</th>\n",
              "      <td>positive</td>\n",
              "      <td>@shamara99 your background is STILL there on m...</td>\n",
              "      <td>USER background still monitor : . go get sleep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343476</th>\n",
              "      <td>negative</td>\n",
              "      <td>Isn't online business great... What a cool gen...</td>\n",
              "      <td>online business great.. cool generation part o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentiment  ...                                  Preprocessed text\n",
              "1406450  positive  ...                             USER that's breakfast \n",
              "1225324  positive  ...                                     beautiful day \n",
              "824245   positive  ...  USER i'm glad someone thinks maple syrup liquo...\n",
              "1270128  positive  ...  USER background still monitor : . go get sleep...\n",
              "343476   negative  ...  online business great.. cool generation part o...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE2JT-YikHf8"
      },
      "source": [
        "data.to_csv('gdrive/MyDrive/Colab Notebooks/Sentiment-Analysis/data/processed_sentiment.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5qZDMgkg5N"
      },
      "source": [
        "##Load processed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "heK6XuJ2kjZ5",
        "outputId": "1a9350e8-46d8-4960-90c2-9a9ff0fa0b01"
      },
      "source": [
        "data = pd.read_csv('gdrive/MyDrive/Colab Notebooks/Sentiment-Analysis/data/processed_sentiment.csv')\n",
        "data.index = data['Unnamed: 0']\n",
        "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "data.index.name = None\n",
        "data['Preprocessed text'] = data['Preprocessed text'].astype(str)\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "      <th>Preprocessed text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1406450</th>\n",
              "      <td>positive</td>\n",
              "      <td>@Alan_Wilbourn That's what we had for breakfas...</td>\n",
              "      <td>USER that's breakfast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225324</th>\n",
              "      <td>positive</td>\n",
              "      <td>Its a beautiful day</td>\n",
              "      <td>beautiful day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824245</th>\n",
              "      <td>positive</td>\n",
              "      <td>@kcmpls I'm glad someone thinks the maple syru...</td>\n",
              "      <td>USER i'm glad someone thinks maple syrup liquo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1270128</th>\n",
              "      <td>positive</td>\n",
              "      <td>@shamara99 your background is STILL there on m...</td>\n",
              "      <td>USER background still monitor : . go get sleep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343476</th>\n",
              "      <td>negative</td>\n",
              "      <td>Isn't online business great... What a cool gen...</td>\n",
              "      <td>online business great.. cool generation part o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentiment  ...                                  Preprocessed text\n",
              "1406450  positive  ...                             USER that's breakfast \n",
              "1225324  positive  ...                                     beautiful day \n",
              "824245   positive  ...  USER i'm glad someone thinks maple syrup liquo...\n",
              "1270128  positive  ...  USER background still monitor : . go get sleep...\n",
              "343476   negative  ...  online business great.. cool generation part o...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24G2cqckfkf6"
      },
      "source": [
        "## Test on smaller dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGByTfm3jeyp"
      },
      "source": [
        "In order to make several test and try different models, we're going to work on a smaller part of the dataset so that the processing doesn't take too long."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-UueQI0jpJz"
      },
      "source": [
        "dev_data = data[:100000]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EjWm-rflXH4"
      },
      "source": [
        "Now let's tokenize the texts so that we can use it to train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHzfmV7hlcHd",
        "outputId": "3763c34d-7fd0-4f72-c1bc-39267177abf7"
      },
      "source": [
        "max_features = 500\n",
        "tokenizer = Tokenizer(\n",
        "    num_words= max_features,\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "    split=\" \"\n",
        ")\n",
        "tokenizer.fit_on_texts(dev_data['Preprocessed text'].values)\n",
        "X = tokenizer.texts_to_sequences(dev_data['Preprocessed text'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8qnQ3_ymCB1"
      },
      "source": [
        "Now that we vectorized the texts, by turning each text into a sequence of integers (each integer being the index of a token in a dictionary), we can create our training data by splitting the data in two part : a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MemjyA8mpu1",
        "outputId": "314501a1-00c3-4ab4-c547-bd440d5448cf"
      },
      "source": [
        "sentiment_label = dev_data.Sentiment.factorize()\n",
        "print(sentiment_label[1])\n",
        "y = sentiment_label[0]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, shuffle=False)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['positive', 'negative'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz33IIMZnyNd"
      },
      "source": [
        "## First model : Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1osvw4ioPZN"
      },
      "source": [
        "expanded_X_train = np.expand_dims(X_train,axis=2)\n",
        "expanded_X_test = np.expand_dims(X_test,axis=2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE0WQHUZohDW",
        "outputId": "945de467-8df9-42bd-aa51-18a90d4f6fd2"
      },
      "source": [
        "input_shape = expanded_X_train[0].shape\n",
        "input_shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22rxN8xdn1hZ",
        "outputId": "894c2a3b-ebe2-422f-acc9-1673548c0434"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(32, input_shape=input_shape))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 32)                1088      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,121\n",
            "Trainable params: 1,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flNeHhK5o1gn",
        "outputId": "5ed58005-577f-46f4-f950-6cd87f8b9f13"
      },
      "source": [
        "model.fit(expanded_X_train, y_train, validation_split=0.2, epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 81s 8ms/step - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6916 - val_accuracy: 0.5020\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 82s 8ms/step - loss: 0.6927 - accuracy: 0.5085 - val_loss: 0.6921 - val_accuracy: 0.5016\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 82s 8ms/step - loss: 0.6922 - accuracy: 0.5075 - val_loss: 0.6921 - val_accuracy: 0.5120\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 83s 8ms/step - loss: 0.6925 - accuracy: 0.5081 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 83s 8ms/step - loss: 0.6922 - accuracy: 0.5119 - val_loss: 0.6907 - val_accuracy: 0.5116\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 84s 8ms/step - loss: 0.6912 - accuracy: 0.5157 - val_loss: 0.6903 - val_accuracy: 0.5174\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 85s 8ms/step - loss: 0.6908 - accuracy: 0.5191 - val_loss: 0.6896 - val_accuracy: 0.5222\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 83s 8ms/step - loss: 0.6907 - accuracy: 0.5200 - val_loss: 0.6901 - val_accuracy: 0.5138\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 83s 8ms/step - loss: 0.6905 - accuracy: 0.5174 - val_loss: 0.6892 - val_accuracy: 0.5227\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 82s 8ms/step - loss: 0.6904 - accuracy: 0.5174 - val_loss: 0.6901 - val_accuracy: 0.5159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f78fd66aa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNcaWFBXp2WC",
        "outputId": "b6f61840-2415-48db-8c0c-c0d64c55c280"
      },
      "source": [
        "loss,acc = model.evaluate(expanded_X_test, y_test)\n",
        "print(\"loss: %.2f\" % (loss))\n",
        "print(\"accuracy: %.2f\" % (acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.6907 - accuracy: 0.5131\n",
            "loss: 0.69\n",
            "accuracy: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3mzPUymqERX"
      },
      "source": [
        "We have a simple RNN model with a sentiment prediction accuracy of about 50%. We can definitely improve this model. Let's try to add an Embedding layer before the SimpleRNN layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnavRIPKr_X_"
      },
      "source": [
        "## Second model : Simple RNN with Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlKc_hANsDYz",
        "outputId": "ad88e374-0cdf-4d02-ff14-f38d998961d9"
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Embedding(max_features, 32, input_length=X.shape[1]))\n",
        "model_2.add(SimpleRNN(32, input_shape=input_shape))\n",
        "model_2.add(Dropout(0.3))\n",
        "model_2.add(Dense(1, activation='sigmoid'))\n",
        "model_2.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "print(model_2.summary())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 35, 32)            16000     \n",
            "_________________________________________________________________\n",
            "simple_rnn_4 (SimpleRNN)     (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 18,113\n",
            "Trainable params: 18,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGPM6PTQsRXH",
        "outputId": "f35fe06c-1603-4557-ceba-768a05891c82"
      },
      "source": [
        "model_2.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=32)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.6099 - accuracy: 0.6493 - val_loss: 0.5416 - val_accuracy: 0.7232\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5389 - accuracy: 0.7250 - val_loss: 0.5429 - val_accuracy: 0.7230\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5323 - accuracy: 0.7301 - val_loss: 0.5449 - val_accuracy: 0.7207\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5268 - accuracy: 0.7357 - val_loss: 0.5457 - val_accuracy: 0.7223\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5218 - accuracy: 0.7399 - val_loss: 0.5489 - val_accuracy: 0.7203\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5199 - accuracy: 0.7398 - val_loss: 0.5503 - val_accuracy: 0.7190\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5168 - accuracy: 0.7420 - val_loss: 0.5536 - val_accuracy: 0.7181\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5169 - accuracy: 0.7435 - val_loss: 0.5521 - val_accuracy: 0.7169\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5183 - accuracy: 0.7411 - val_loss: 0.5505 - val_accuracy: 0.7201\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5100 - accuracy: 0.7477 - val_loss: 0.5536 - val_accuracy: 0.7167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22d508eb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OElhYJTIB2rD",
        "outputId": "c55e4a57-6e7d-44e8-e1cb-917c94ca9c11"
      },
      "source": [
        "loss,acc = model_2.evaluate(X_test, y_test)\n",
        "print(\"loss: %.2f\" % (loss))\n",
        "print(\"accuracy: %.2f\" % (acc))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5536 - accuracy: 0.7142\n",
            "loss: 0.55\n",
            "accuracy: 0.71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R0xwoMQDpiV"
      },
      "source": [
        "## Third model : LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3oTIZvGDpiV",
        "outputId": "2c790854-4013-4bc4-89a8-f0693a9e3d02"
      },
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Embedding(max_features, 32, input_length=X.shape[1]))\n",
        "model_3.add(SpatialDropout1D(0.4))\n",
        "model_3.add(LSTM(64, recurrent_dropout=0.2, dropout=0.2))\n",
        "model_3.add(Dense(64, activation='relu'))\n",
        "model_3.add(Dropout(0.3))\n",
        "model_3.add(Dense(1, activation='sigmoid'))\n",
        "model_3.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "print(model_3.summary())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 35, 32)            16000     \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 35, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 45,057\n",
            "Trainable params: 45,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbi-gHYBDpiW",
        "outputId": "ee3a3ffd-692d-49df-a2ac-d1d2dfbb3a76"
      },
      "source": [
        "model_3.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=32)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 80s 39ms/step - loss: 0.5977 - accuracy: 0.6648 - val_loss: 0.5410 - val_accuracy: 0.7219\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 77s 39ms/step - loss: 0.5513 - accuracy: 0.7180 - val_loss: 0.5377 - val_accuracy: 0.7229\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 78s 39ms/step - loss: 0.5424 - accuracy: 0.7239 - val_loss: 0.5347 - val_accuracy: 0.7243\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 78s 39ms/step - loss: 0.5377 - accuracy: 0.7281 - val_loss: 0.5337 - val_accuracy: 0.7258\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 78s 39ms/step - loss: 0.5354 - accuracy: 0.7285 - val_loss: 0.5338 - val_accuracy: 0.7260\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 77s 39ms/step - loss: 0.5339 - accuracy: 0.7271 - val_loss: 0.5311 - val_accuracy: 0.7272\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 78s 39ms/step - loss: 0.5292 - accuracy: 0.7323 - val_loss: 0.5337 - val_accuracy: 0.7289\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 78s 39ms/step - loss: 0.5280 - accuracy: 0.7339 - val_loss: 0.5342 - val_accuracy: 0.7268\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 77s 39ms/step - loss: 0.5278 - accuracy: 0.7321 - val_loss: 0.5413 - val_accuracy: 0.7296\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 78s 39ms/step - loss: 0.5259 - accuracy: 0.7334 - val_loss: 0.5337 - val_accuracy: 0.7290\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22d050c950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNZ4LWHrDpiW",
        "outputId": "73c7b8b1-be8c-431d-ab75-da89ab504989"
      },
      "source": [
        "loss,acc = model_3.evaluate(X_test, y_test)\n",
        "print(\"loss: %.2f\" % (loss))\n",
        "print(\"accuracy: %.2f\" % (acc))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 4s 7ms/step - loss: 0.5297 - accuracy: 0.7308\n",
            "loss: 0.53\n",
            "accuracy: 0.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MiXtdQXItAY"
      },
      "source": [
        "##Prediction Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqVbCOhnIv0g"
      },
      "source": [
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(urlPattern,' URL',text)\n",
        "  for emoji in emojis.keys():\n",
        "      text = text.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
        "  text = re.sub(userPattern,' USER', text)        \n",
        "  text = re.sub(alphaPattern, \" \", text)\n",
        "  text = re.sub(sequencePattern, seqReplacePattern, text)\n",
        "\n",
        "  preprocessed = \"\"\n",
        "  for word in text.split():\n",
        "    if not word in list(nltk.corpus.stopwords.words('english')):\n",
        "      preprocessed += (word + ' ')\n",
        "\n",
        "  return preprocessed"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvV17nzRKyt1"
      },
      "source": [
        "def prediction(text):\n",
        "  preprocessed = preprocess(text)\n",
        "  preprocessed = tokenizer.texts_to_sequences([preprocessed])\n",
        "  preprocessed = pad_sequences(preprocessed, maxlen=X.shape[1])\n",
        "  prediction = model_3.predict(preprocessed)[0][0]\n",
        "  if prediction > 0.5:\n",
        "    print(sentiment_label[1][1])\n",
        "  else:\n",
        "    print(sentiment_label[1][0])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R89crX9yLH_k",
        "outputId": "8250683a-d617-419c-f369-a0414c4c0352"
      },
      "source": [
        "prediction('I love Mondays and Wednesdays !')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}